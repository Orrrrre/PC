# Point Cloud

## PointNet

æ¥è‡ªè¿™ç¯‡[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/336496973)
![PointNet](./pics/pointnet.jpg "architecture")

1. å˜æ¢çŸ©é˜µï¼ˆ**T-Net**ï¼‰
![T-Net](pics/T-Net.jpg)
ä¸ºäº†ä¿è¯è¾“å…¥ç‚¹äº‘çš„**ä¸å˜æ€§**ï¼Œä½œè€…åœ¨è¿›è¡Œç‰¹å¾æå–å‰å…ˆå¯¹ç‚¹äº‘æ•°æ®è¿›è¡Œ**å¯¹é½æ“ä½œ**ï¼šå› ä¸ºç‚¹äº‘ä»å„ä¸ªæ–¹å‘ä¸Šè§‚æµ‹è™½ç„¶ä¸åŒï¼Œä½†å…¶è¡¨ç¤ºçš„æ˜¯åŒä¸€ä¸ªç‰©ä½“ï¼Œå› æ­¤å¯ä»¥å¯¹é½åˆ°ä¸€ä¸ªç©ºé—´ä¸Šï¼ˆä¹Ÿå°±æ˜¯input transformï¼‰ã€‚  
**å¯¹é½æ“ä½œ**æ˜¯é€šè¿‡è®­ç»ƒä¸€ä¸ªå°å‹çš„ç½‘ç»œï¼ˆä¹Ÿå°±æ˜¯ä¸Šå›¾ä¸­çš„T-Netï¼‰æ¥å¾—åˆ°**è½¬æ¢çŸ©é˜µ**ï¼Œå†å°†è½¬æ¢çŸ©é˜µä¸è¾“å…¥ç›¸ä¹˜å®ç°çš„ã€‚

```python
class STN3d(nn.Module):
    def __init__(self, channel):
        super(STN3d, self).__init__()
        self.conv1 = torch.nn.Conv1d(channel, 64, 1)
        self.conv2 = torch.nn.Conv1d(64, 128, 1)
        self.conv3 = torch.nn.Conv1d(128, 1024, 1)
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 9)
        self.relu = nn.ReLU()

        self.bn1 = nn.BatchNorm1d(64)
        self.bn2 = nn.BatchNorm1d(128)
        self.bn3 = nn.BatchNorm1d(1024)
        self.bn4 = nn.BatchNorm1d(512)
        self.bn5 = nn.BatchNorm1d(256)

    def forward(self, x):
        batchsize = x.size()[0]  # shape (batch_size,3,point_nums)
        x = F.relu(self.bn1(self.conv1(x)))  # shape (batch_size,64,point_nums)
        x = F.relu(self.bn2(self.conv2(x)))  # shape (batch_size,128,point_nums)
        x = F.relu(self.bn3(self.conv3(x)))  # shape (batch_size,1024,point_nums)
        x = torch.max(x, 2, keepdim=True)[0]  # shape (batch_size,1024,1)
        x = x.view(-1, 1024) # shape (batch_size,1024)

        x = F.relu(self.bn4(self.fc1(x)))  # shape (batch_size,512)
        x = F.relu(self.bn5(self.fc2(x)))  # shape (batch_size,256)
        x = self.fc3(x)  # shape (batch_size,9)

        """
        æœ€ç»ˆçš„ 3*3å˜æ¢çŸ©é˜µ æ˜¯è¦ä¸ n*3çš„ç‚¹äº‘çŸ©é˜µ ç›¸ä¹˜æ¥å®ç°å˜æ¢çš„ï¼Œè€Œå®é™…ä¸Šå…¶å®šä¹‰å˜æ¢ä¹˜æ³•æ˜¯ï¼š
        è¾“å…¥ çŸ©é˜µä¹˜ å˜æ¢çŸ©é˜µ + è¾“å…¥(æ·»åŠ æ’ç­‰å˜æ¢)ï¼Œè¿™ä¸ªæ’ç­‰å˜æ¢æ˜¯é€šè¿‡åœ¨ä¸­é—´çŸ©é˜µæ·»åŠ idenå®ç°çš„
        """ 
        # idenè¡¨ç¤ºä¸€ä¸ªå¯¹è§’é˜µ(1å¡«å……çš„)
        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(
            batchsize, 1)  # shape (batch_size,9)
        if x.is_cuda:
            iden = iden.cuda()
        # that's the same thing as adding a diagonal matrix(full 1)
        x = x + iden  # iden means that add the input-self
        x = x.view(-1, 3, 3) # shape (batch_size,3,3)
        return x  # å¾—åˆ°çš„xæ˜¯å˜æ¢çŸ©é˜µ3*3
```

å’Œä¸Šé¢çš„input transformçŸ©é˜µçš„è·å–æ–¹å¼ç±»ä¼¼ï¼Œfeature transformçš„`64*64`çŸ©é˜µè·å–ä»£ç å®ç°å¦‚ä¸‹ï¼š

```python
class STNkd(nn.Module):
    def __init__(self, k=64):
        super(STNkd, self).__init__()
        self.conv1 = torch.nn.Conv1d(k, 64, 1)
        self.conv2 = torch.nn.Conv1d(64, 128, 1)
        self.conv3 = torch.nn.Conv1d(128, 1024, 1)
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, k * k)
        self.relu = nn.ReLU()

        self.bn1 = nn.BatchNorm1d(64)
        self.bn2 = nn.BatchNorm1d(128)
        self.bn3 = nn.BatchNorm1d(1024)
        self.bn4 = nn.BatchNorm1d(512)
        self.bn5 = nn.BatchNorm1d(256)

        self.k = k

    def forward(self, x):
        batchsize = x.size()[0]
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        x = torch.max(x, 2, keepdim=True)[0]
        x = x.view(-1, 1024)

        x = F.relu(self.bn4(self.fc1(x)))
        x = F.relu(self.bn5(self.fc2(x)))
        x = self.fc3(x)

        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(
            batchsize, 1)
        if x.is_cuda:
            iden = iden.cuda()
        x = x + iden
        x = x.view(-1, self.k, self.k)
        return x
```

å…¶åœ¨**åˆ†å‰²**ä»»åŠ¡ä¸Šçš„è¿˜åŸè¿‡ç¨‹ï¼š
![PointNet](./pics/pointnet.jpg "æ³¨æ„å›¾ç‰‡ä¸‹åŠéƒ¨åˆ†ï¼ˆåˆ†å‰²ï¼‰")
è¿™ä¸ª`n*1088`çš„å¼ é‡ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¸€ä¸ªæ˜¯**ç‰¹å¾æå–ç½‘ç»œçš„è¾“å‡º**ï¼ˆå¤§å°ä¸º`n*64`ï¼‰,å¦ä¸€ä¸ªæ˜¯é€šè¿‡maxpoolingåçš„global featureï¼ˆå¤§å°ä¸º1024ï¼‰ï¼Œåœ¨è¿›è¡Œä¸¤è€…èåˆçš„æ—¶å€™ï¼Œå¯¹global featureè¿›è¡Œäº†å¹¿æ’­ï¼Œé‚£ä¹ˆ`64+1024`å°±æ˜¯`1088`äº†ã€‚ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšå‘¢ï¼Ÿ:ç­”æ¡ˆå°±æ˜¯ä½œè€…æƒ³è¦èåˆ**ç‚¹çš„ç‰¹å¾ä¿¡æ¯**ï¼ˆæ¥è‡ªç‰¹å¾æå–ç½‘ç»œçš„è¾“å‡ºï¼‰ä¸**å…¨å±€ç‰¹å¾**ï¼ˆæ¥è‡ªglobal featureï¼‰ã€‚

> **ç¼ºç‚¹**ï¼šä¸€ç›´åœ¨é€šè¿‡mlpè¿›è¡Œå•ä¸ªç‚¹å†…çš„ä¿¡æ¯äº¤äº’ï¼Œæœ€åé€šè¿‡Max Poolingåªè¿›è¡Œäº†ä¸€æ¬¡å…¨å±€ä¿¡æ¯çš„äº¤äº’ï¼Œç¼ºå°‘ä¸­é—´å°ºåº¦çš„ä¿¡æ¯äº¤äº’(å¦‚CNNä¸­çš„é€å°ºåº¦ä¸‹é‡‡æ ·ç‰¹å¾æå–)ï¼Œç¼ºå°‘å±€éƒ¨ç‰¹å¾ä¿¡æ¯ã€‚

ğŸ‘‡

## PointNet++

> **Sampling Layer + Grouping Layer**  

### **æœ€è¿œç‚¹é‡‡æ ·ç®—æ³•(FPS)**æ¥å®ç°ä»`N`ä¸ªç‚¹ä¸­é‡‡æ ·`N'`ä¸ªç‚¹ğŸ‘‰**Sampling Layer**

1. éšæœºé€‰æ‹©ä¸€ä¸ªç‚¹ä½œä¸º**åˆå§‹ç‚¹**ä½œä¸º**å·²é€‰æ‹©é‡‡æ ·ç‚¹**
2. è®¡ç®—**æœªé€‰æ‹©é‡‡æ ·ç‚¹é›†**ä¸­æ¯ä¸ªç‚¹ä¸**å·²é€‰æ‹©é‡‡æ ·ç‚¹é›†**ä¹‹é—´çš„è·ç¦»distanceï¼Œå°†**è·ç¦»æœ€å¤§**çš„é‚£ä¸ªç‚¹åŠ å…¥å·²é€‰æ‹©é‡‡æ ·ç‚¹é›†
3. æ›´æ–°distanceï¼Œä¸€ç›´å¾ªç¯è¿­ä»£ä¸‹å»ï¼Œç›´è‡³è·å¾—äº†ç›®æ ‡æ•°é‡çš„é‡‡æ ·ç‚¹ã€‚

```python
def farthest_point_sample(xyz, npoint):
    """
    Input:
        xyz: pointcloud data, [B, N, 3]
        npoint: number of samples
    Return:
        centroids: sampled pointcloud index, [B, npoint]
    """
    device = xyz.device
    B, N, C = xyz.shape  # (B, N, 3)
    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)  # åˆå§‹åŒ–ç›®æ ‡é‡‡æ ·ç‚¹(B, npoint)
    distance = torch.ones(B, N).to(device) * 1e10  # (B, N)
    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)  # (B,)è¡¨ç¤ºåœ¨batchä¸­çš„ æ¯ä¸€ä¸ªæ ·æœ¬ é‡Œéšæœºåˆå§‹åŒ–ä¸€ä¸ªç‚¹ä½œä¸ºåŸºå‡†(åŒ…å«çš„æ˜¯æœ€è¿œç‚¹çš„idx)
    batch_indices = torch.arange(B, dtype=torch.long).to(device)  # ç­‰äºåœ¨åˆ‡ç‰‡ä¸­ç›´æ¥å†™":"
    for i in range(npoint):
        centroids[:, i] = farthest  # (b, npoint)
        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)  # (B, 3) -> (B, 1, 3)
        dist = torch.sum((xyz - centroid) ** 2, -1)  # (B, N, 3) - (B, 1, 3) -> dist(B, N):é€‰å‡ºæ¥çš„ç‚¹ä¸æ‰€æœ‰ç‚¹çš„æœ€å°äºŒä¹˜(åŒ…å«çš„æ˜¯å½“å‰ç‚¹ä¸æ‰€æœ‰ç‚¹çš„è·ç¦»)
        mask = dist < distance  # ä½ ä¸ä¸Šä¸€ä¸ªæœ€è¿œç‚¹çš„è·ç¦»è‚¯å®šæ˜¯å¤§äºå½“å‰è®¡ç®—çš„æ‰€æœ‰çš„distï¼Œå› æ­¤ä¸Šä¸€ä¸ªæœ€è¿œç‚¹å¤„ä¼šè¢«æ ‡ä¸ºfalseï¼Œé¿å…é€‰ç‚¹æ¥å›åœ¨ä¸¤ä¸ªæœ€è¿œç‚¹ä¹‹é—´è·³æ‘†ã€‚çœ‹ä¸‹æ–¹ç¤ºä¾‹ğŸ‘‡
        distance[mask] = dist[mask]  # æ›´æ–°distanceä¸ºæ’é™¤æ‰€é€‰æœ€è¿œç‚¹ä¹‹åçš„å€¼
        farthest = torch.max(distance, -1)[1]  # å–[1]æ˜¯å› ä¸ºè¿”å›ç»“æœå…ƒç»„ä¸­çš„ç¬¬äºŒé¡¹æ˜¯idx
    return centroids
#  å½“B=4ï¼Œ N=5, npoint=3æ—¶çš„ç»“æœ
>>ğŸ‘‡
farthest0:                                  farthest1:
tensor([0, 3, 4, 2])                        tensor([1, 0, 1, 0])
dist:                                       dist:
tensor([[   0, 9821, 4853, 5709, 4358],     tensor([[9821,    0, 5082, 1856, 9011],
        [1787,  708, 1469,    0, 1217],             [   0, 3955, 3362, 1787, 1702],
        [7178, 9595, 8797, 4309,    0],             [4497,    0,  694, 1314, 9595],
        [3924,  801,    0, 1294,  152]])            [   0, 3589, 3924, 1986, 3948]])
mask:                                       mask:#å¯çœ‹åˆ°ä¸Šä¸€æ¬¡é€‰è¿‡çš„ç‚¹å¤„å·²ç»è¢«æ ‡ä¸ºäº†False
tensor([[True, True, True, True, True],     tensor([[False,  True, False,  True, False],
        [True, True, True, True, True],             [ True, False, False, False, False],
        [True, True, True, True, True],             [ True,  True,  True,  True, False],
        [True, True, True, True, True]])            [ True, False, False, False, False]])
distance:                                   distance:
tensor([[   0, 9821, 4853, 5709, 4358],     tensor([[   0,    0, 4853, 1856, 4358],
        [1787,  708, 1469,    0, 1217],             [   0,  708, 1469,    0, 1217],
        [7178, 9595, 8797, 4309,    0],             [4497,    0,  694, 1314,    0],
        [3924,  801,    0, 1294,  152]])            [   0,  801,    0, 1294,  152]])

farthest2:
tensor([2, 2, 0, 3])
dist:
tensor([[ 4853,  5082,     0,  6410, 12753],
        [ 3362,  3413,     0,  1469,  5022],
        [    0,  4497,  2379,  3681,  7178],
        [ 1986,   321,  1294,     0,  1126]])
mask:
tensor([[False, False,  True, False, False],
        [False, False,  True, False, False],
        [ True, False, False, False, False],
        [False,  True, False,  True, False]])
distance:
tensor([[   0,    0,    0, 1856, 4358],
        [   0,  708,    0,    0, 1217],
        [   0,    0,  694, 1314,    0],
        [   0,  321,    0,    0,  152]])
```

ğŸ‘‡  
**å¦‚ä½•å°†ç‚¹é›†åˆ’åˆ†ä¸ºä¸åŒçš„åŒºåŸŸï¼Œå¹¶è·å–ä¸åŒåŒºåŸŸçš„å±€éƒ¨ç‰¹å¾ï¼Ÿ**

### Ball query(groupç­–ç•¥)ğŸ‘‰**Grouping Layer**

1. é¢„è®¾**æœç´¢åŒºåŸŸ**çš„åŠå¾„`R`ä¸**å­åŒºåŸŸ**çš„ç‚¹æ•°`K`
2. æ ¹æ®ä¸Šé¢æå–çš„`N'`ç¡®å®šcentriodsæ•°é‡ï¼Œä»¥`N'`ä¸ªç‚¹ä¸ºçƒå¿ƒï¼Œç”»åŠå¾„ä¸º`R`çš„çƒä½“ï¼ˆå«åš`query ball`ï¼Œä¹Ÿå°±æ˜¯æœç´¢åŒºåŸŸï¼‰ã€‚
3. åœ¨æ¯ä¸ªä»¥centriodsçš„çƒå¿ƒçš„çƒä½“å†…æœç´¢ç¦»centriodsæœ€è¿‘çš„çš„ç‚¹ï¼ˆæŒ‰ç…§è·ç¦»ä»å°åˆ°å¤§æ’åºï¼Œæ‰¾åˆ°`K`ä¸ªç‚¹ï¼‰ã€‚å¦‚æœ`query ball`çš„ç‚¹æ•°é‡å¤§äºç‚¹æ•°`K`ï¼Œé‚£ä¹ˆç›´æ¥å–å‰`K`ä¸ªä½œä¸ºå­åŒºåŸŸï¼›(**å¦‚æœå°äºï¼Œé‚£ä¹ˆç›´æ¥å¯¹æŸä¸ªç‚¹é‡é‡‡æ ·ï¼Œå‡‘å¤Ÿè§„æ¨¡`K`**ä¸æ˜¯å¾ˆç†è§£å¦‚ä½•é‡é‡‡æ ·)

ğŸ‘‡  

### è¿›è¡Œå±€éƒ¨ç‰¹å¾çš„æå– **Set Abstraction(SA)**

> é€šè¿‡Sample layerå’ŒGrounping layeråï¼Œç½‘ç»œåé¢ç´§è·Ÿç€ä¸€ä¸ªpointnetæ¥è¿›è¡ŒåŒºåŸŸç‰¹å¾æå–  
![pointnet_in_PN++](./pics/pointnet_in_PN++.jpg)  
ä½œè€…å°†max poolç”¨åœ¨å­åŒºåŸŸä¸Šï¼Œå®ç°**åŒºåŸŸ**ç‰¹å¾æå–  
`Sample layer/Grounping layer/Pointnet`ï¼ˆä¸‰ä¸ªåˆåœ¨ä¸€èµ·å«åš`set abstraction`ï¼‰

ä¸€ä¸ª`set abstraction`ä»£ç å¦‚ä¸‹ï¼š

```python
def square_distance(src, dst):  # new_xyz(centroieds)[B, S, C]  xyz[B, N, C]
    """
    Calculate Euclid distance between each two points.

    src^T * dst = xn * xm + yn * ym + zn * zm;
    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;
    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;
    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2
         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst

    Input:
        src: source points, [B, N, C]
        dst: target points, [B, M, C]
    Output:
        dist: per-point square distance, [B, N, M]
    """
    B, N, _ = src.shape
    _, M, _ = dst.shape

    #  (src-dst)**2
    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))  # -2src*dst  (B, S, C)MM(B, C, N)->(B, S, N)
    dist += torch.sum(src ** 2, -1).view(B, M, 1)  # src**2  (B, S)->(B, S, 1) + (B, S, N)
    dist += torch.sum(dst ** 2, -1).view(B, 1, N)  # dst**2  (B, N)->(B, 1, N) + (B, S, N)
    return dist  # (B, S, N)
>>             
  â€”â€”â€”â€”â€”â€”>     S1 S2     dist*(-2)       P^2[3, 1]    S^2[1, 2]        final_dist[B, 3, 2]
  P1@ @ @      * *|      @* @*              (Î£@^2)                   (@*+Î£@^2+Î£*^2, @*+Î£@^2+Î£*^2)
  P2@ @ @  MM  * *|  ->  @* @*  *(-2)  -> + (Î£@^2)  + (Î£*^2, Î£*^2) ->(@*+Î£@^2+Î£*^2, @*+Î£@^2+Î£*^2)
  P3@ @ @      * *â†“      @* @*              (Î£@^2)                   (@*+Î£@^2+Î£*^2, @*+Î£@^2+Î£*^2)

def query_ball_point(radius, nsample, xyz, new_xyz):#  è¿™é‡Œå®˜æ–¹æºä»£ç ä¸­æœ‰è¯¯ï¼Œåšäº†ä¸€äº›æ›´æ”¹
    """
    Input:
        radius: local region radius
        nsample: max sample number in local region
        xyz: all points, [B, N, 3]
        new_xyz: query points, [B, S, 3]
    Return:
        group_idx: grouped points index, [B, S, nsample]
    """
    device = xyz.device
    B, N, C = xyz.shape
    _, S, _ = new_xyz.shape
    # group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])

    sqrdists = square_distance(new_xyz, xyz)  # (B, S, N)æ¯ä¸ªé‡‡æ ·ä¸­å¿ƒåˆ°å„ä¸ªç‚¹çš„æ¬§å¼è·ç¦»çš„å¹³æ–¹

    # (B, S, N) group_idxå…¶ä¸­çš„å€¼ä¸º0~N-1
    sort_dis, group_idx = sqrdists.sort(dim=-1)  # group_idx(B, S, N)å‡åºæ’åºåçš„group_idx
    group_idx[sort_dis > radius ** 2] = N  # ç´¢å¼•çš„èŒƒå›´ä¸º0~N-1ï¼Œæ‰€ä»¥Næ˜¯ä¸å­˜åœ¨çš„ï¼Œå› æ­¤å¯å°†è¶…å‡ºèŒƒå›´çš„idxç½®ä¸ºN
    group_idx = group_idx[:, :, :nsample]  # (B, S, nsample)å…¶ä¸­æœ€åå‡ ä¸ªidxæœ‰å¯èƒ½æ˜¯N(groupä¸­ç‚¹ä¸è¶³)

    # ğŸ‘‡å½“groupä¸­çš„ç‚¹ä¸è¶³nsampleä¸ªæ—¶ï¼Œä½¿ç”¨ç¦»é‡‡æ ·ä¸­å¿ƒæœ€è¿‘çš„ç‚¹æ¥å¡«å……
    # æ„å»ºä¸€ä¸ªç”±å½“å‰batchä¸­è·ç¦»æ¯ä¸€ä¸ªæ ·æœ¬ä¸­å¿ƒæœ€è¿‘çš„ç‚¹(first point)å¡«å……çš„çŸ©é˜µ(B, S, nsample)
    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])
    # ä»æ’åºä¸”ç­›é€‰nsampleé¡¹çš„groupe_idxä¸­æ‰¾å‡ºæ‰€æœ‰idxä¸ºNçš„ç‚¹
    mask = group_idx == N
    # å°†æ’åºä¸”ç­›é€‰nsampleé¡¹çš„groupe_idxä¸­çš„idxä¸ºNçš„ç‚¹æ›¿æ¢ä¸ºfirst pointçš„idx
    group_idx[mask] = group_first[mask]  
    return group_idx

def index_points(points, idx):
    """
    Input:
        points: input points data, [B, N, C]
        idx: sample index data, [B, S]
    Return:
        new_points:, indexed points data, [B, S, C]
    """
    device = points.device
    B = points.shape[0]
    view_shape = list(idx.shape)  # [B, S]
    view_shape[1:] = [1] * (len(view_shape) - 1)
    repeat_shape = list(idx.shape)  # [B, S]
    repeat_shape[0] = 1  # [1, S]
    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)
    new_points = points[batch_indices, idx, :]
    return new_points
>>  # è§£é‡Šä¸€ä¸‹batch_indicesä¸­çš„viewå’Œrepeatï¼š
ä»¥ä¸‹é¢çš„ä¸ºä¾‹ï¼š
    a = torch.randint(0, 8, (3, 3, 4))  # è¡¨ç¤ºåŸç‚¹é›†B=3, N=3, C=4
    idx2 = torch.tensor([[0, 1], [1, 2], [0, 2]])  # è¡¨ç¤ºfarthesté‡‡æ ·å‡ºæ¥çš„centroiedsçš„idx,å½¢çŠ¶ä¸º(B, S)åœ¨è¿™ä¸ªä¾‹å­ä¸­S=2
    idx = torch.arange(3).view((3, 1)).repeat(1, 2)  # è¡¨ç¤ºå°†idx:[0, 1, ..., B-1]viewä¸repeatåidxçš„å½¢çŠ¶ä¸º(B, S),ç›®çš„æ˜¯ä¸ç¬¬äºŒç»´åº¦ç´¢å¼•å½¢çŠ¶ç›¸åŒï¼Œè¿™æ ·æ‰èƒ½å¯¹åº”ä½ç½®ç´¢å¼•åˆ°ç‚¹é›†ã€‚

a:                        idxï¼š           
tensor([[[2, 7, 3, 6],    tensor([[0, 0],                 
         [6, 4, 4, 4],            [1, 1],                 
         [1, 6, 0, 2]],           [2, 2]])                  
                          idx[2]:        
        [[7, 2, 6, 2],    tensor([[0, 1],                 
         [0, 1, 6, 1],            [1, 2],                 
         [1, 5, 3, 6]],           [0, 2]])                   
                                    
        [[3, 1, 4, 0],                    
         [0, 0, 7, 3],                                    
         [0, 3, 7, 3]]])                  
                                                       
                                    
a[idx, idx2, :]:  # (B, S, C)                                         
tensor([[[2, 7, 3, 6],                                     
         [6, 4, 4, 4]],                            
                                    
        [[0, 1, 6, 1],                    
         [1, 5, 3, 6]],                                    
                                                  
        [[3, 1, 4, 0],
         [0, 3, 7, 3]]])

def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):
    """
    Input:
        npoint:
        radius:
        nsample:
        xyz: input points position data, [B, N, 3]
        points: input points data, [B, N, D]
    Return:
        new_xyz: sampled points position data, [B, npoint, nsample, 3]
        new_points: sampled points data, [B, npoint, nsample, 3+D]
    """
    B, N, C = xyz.shape
    S = npoint
    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]
    new_xyz = index_points(xyz, fps_idx)  # [B, S, C]
    idx = query_ball_point(radius, nsample, xyz, new_xyz)
    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]
    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)

    if points is not None:
        grouped_points = index_points(points, idx)
        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]
    else:
        new_points = grouped_xyz_norm
    if returnfps:
        return new_xyz, new_points, grouped_xyz, fps_idx
    else:
        return new_xyz, new_points

class PointNetSetAbstraction(nn.Module):
    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):
        super(PointNetSetAbstraction, self).__init__()
        self.npoint = npoint
        self.radius = radius
        self.nsample = nsample
        self.mlp_convs = nn.ModuleList()
        self.mlp_bns = nn.ModuleList()
        last_channel = in_channel
        for out_channel in mlp:
            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))  # è™½ç„¶Conv2dï¼Œä½†æ˜¯1* 1çš„å·ç§¯ğŸ˜µ
            self.mlp_bns.append(nn.BatchNorm2d(out_channel))
            last_channel = out_channel
        self.group_all = group_all

    def forward(self, xyz, points):
        """
        Input:
            xyz: input points position data, [B, C, N]
            points: input points data, [B, D, N]
        Return:
            new_xyz: sampled points position data, [B, C, S]
            new_points_concat: sample points feature data, [B, D', S]
        """
        xyz = xyz.permute(0, 2, 1)  # (B, N, C)
        if points is not None:
            points = points.permute(0, 2, 1)  # (B, N, D)

        if self.group_all:
            new_xyz, new_points = sample_and_group_all(xyz, points)  # é‡‡æ ·è¦†ç›–æ‰€æœ‰ç‚¹
        else:
            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)
        # new_xyz: sampled points position data, [B, npoint, C]
        # new_points: sampled points data, [B, npoint, nsample, C+D]
        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample, npoint]
        for i, conv in enumerate(self.mlp_convs):
            bn = self.mlp_bns[i]
            new_points =  F.relu(bn(conv(new_points)))

        new_points = torch.max(new_points, 2)[0]
        new_xyz = new_xyz.permute(0, 2, 1)
        return new_xyz, new_points
```

> **ç¼ºç‚¹**ï¼šæ¥æºäºsamplingå’Œgroupingçš„åœ¨é‡åˆ°**éå‡åŒ€åˆ†å¸ƒ**çš„ç‚¹äº‘é›†åˆæ—¶ï¼š
>  
> `It is common that a point set comes with` **nonuniform density** `in` **different areas**  
> `Features learned in` **dense** `data may` **not generalize to** **sparsely** `sampled regions`

äºæ˜¯ä½œè€…æå‡ºäº†**ä¸¤ç§ç‰¹å¾èåˆæ–¹å¼**ï¼Œåˆ†åˆ«ä¸ºï¼š

1. Multi-scale grouping (MSG):æ˜¯å¯¹ä¸åŒåŠå¾„çš„å­åŒºåŸŸè¿›è¡Œç‰¹å¾æå–åè¿›è¡Œç‰¹å¾å †å ,MSGæ–¹æ³•è®¡ç®—é‡å¤ªå¤§ï¼Œæå‡ºæ¥çš„å¤‡é€‰æ–¹æ¡ˆMRG
2. Multiresolution grouping (MRG):MRGç”¨ä¸¤ä¸ªPointnetå¯¹è¿ç»­çš„ä¸¤å±‚åˆ†åˆ«åšç‰¹å¾æå–ä¸èšåˆï¼Œç„¶åå†è¿›è¡Œç‰¹å¾æ‹¼æ¥ã€‚

![msg& mrg](pics/MSG&%20MRG.jpg "")

MSG:

```python
  B, N, C = xyz.shape
  S = self.npoint
  new_xyz = index_points(xyz, farthest_point_sample(xyz, S))
  new_points_list = []
  for i, radius in enumerate(self.radius_list):
      K = self.nsample_list[i]
      group_idx = query_ball_point(radius, K, xyz, new_xyz)
      grouped_xyz = index_points(xyz, group_idx)
      grouped_xyz -= new_xyz.view(B, S, 1, C)
      if points is not None:
          grouped_points = index_points(points, group_idx)
          grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)
      else:
          grouped_points = grouped_xyz

      grouped_points = grouped_points.permute(0, 3, 2, 1)  # [B, D, K, S]
      for j in range(len(self.conv_blocks[i])):
          conv = self.conv_blocks[i][j]
          bn = self.bn_blocks[i][j]
          grouped_points =  F.relu(bn(conv(grouped_points)))
      new_points = torch.max(grouped_points, 2)[0]  # [B, D', S]
      new_points_list.append(new_points)

  new_xyz = new_xyz.permute(0, 2, 1)
  new_points_concat = torch.cat(new_points_list, dim=1)
```

## VoxelNet

æ¥è‡ª[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/352419316)

### ç‰¹å¾å­¦ä¹ ç½‘ç»œ

1. **Voxel Partition**ï¼šä¹Ÿå°±æ˜¯å°†ç©ºé—´åˆ’åˆ†ä¸ºä¸€ä¸ªä¸ªå †å çš„ã€ç›¸åŒå¤§å°çš„Voxel
2. **Grouping**ï¼šä¸Šé¢å°†ç©ºé—´åˆ’åˆ†ä¸ºä¸€ä¸ªä¸ªçš„Voxeläº†ï¼ŒGroupingè¿™ä¸€æ­¥çš„ä½œç”¨å°±æ˜¯å°†3D**ç‚¹äº‘æ•°æ®è£…è¿›è¿™ä¸€ä¸ªä¸ªçš„Voxelä¸­**ï¼Œå®ç°åˆ†ç»„ã€‚
3. **Random Sampling**ï¼š3Dç‚¹äº‘çš„æ•°æ®é‡å¾€å¾€éƒ½æ˜¯10ä¸‡ä»¥ä¸Šçš„ã€‚è¦æ˜¯ç›´æ¥åœ¨è¿™ä¸ªæ•°é‡çº§ä¸Šè¿›è¡Œç‰¹å¾æå–ï¼Œæ˜¯éå¸¸æ¶ˆè€—è®¡ç®—èµ„æºçš„ï¼Œè€Œä¸”å¯èƒ½ä¼šå¼•å‘æ£€æµ‹åå·®ï¼ˆbias the detectionï¼‰ã€‚æ‰€ä»¥ä½œè€…æå‡ºäº†éšæœºé‡‡æ ·æ–¹æ³•ï¼Œå°†**ç‚¹äº‘æ•°é‡è¶…è¿‡`T`çš„Voxel**ä¸­çš„ç‚¹äº‘æ•°é‡é™è‡³`T`ã€‚
4. **Stacked Voxel Feature Encoding**ï¼šè¿™ä¸€æ­¥æ˜¯æœ€é‡è¦çš„ä¸€æ­¥ã€‚ä½œè€…åœ¨è¿™ä¸€æ­¥æå‡ºäº†VFEå±‚ï¼ˆVFE= Voxel Feature Encodingï¼‰ã€‚æˆ‘ç›¸ä¿¡ä½œè€…æå‡ºè¿™ä¸ªå±‚ï¼Œåº”è¯¥æ˜¯å—åˆ°äº†PointNetçš„å¯å‘ã€‚è¿™é‡Œæˆ‘ä»¬ç»™å‡ºè¿™ä¸ªå±‚çš„å®ç°å›¾
![VFE](./pics/VFE.jpg "VFE")  
    1. ä¸Šå›¾ä¸­Voxelæœ‰**3ä¸ª**ç‚¹äº‘æ•°æ®ã€‚ä½œè€…å…ˆç”¨ä¸€ä¸ªFCNå±‚(**é€ç‚¹è®¡ç®—**ï¼Œå¹¶æ²¡æœ‰å¼•å…¥ç‚¹ä¸ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œä¹Ÿå°±æ˜¯local featureï¼Œæ‰€ä»¥FCNæŒ‡çš„æ˜¯å…¨è¿æ¥å±‚)
    ä½œè€…åœ¨æ­¤åŸºç¡€ä¸Šå¼•å…¥**Element-wise maxpool**ï¼Œè·å¾—**Locally Aggregated Feature**ã€‚Locally Aggregated Featureååº”äº†è¿™äº›ç‚¹çš„ä¸€ä¸ªå±€éƒ¨å…³ç³»ã€‚(å¯¹åº”ä¸Šå›¾ä¸­ç¬¬äºŒä¸ªç™½æ¡†)  
    2. ä½œè€…å°†Point-wise Featureå’ŒLocally Aggregated Featureè¿›è¡Œäº†ç®€å•çš„å †å èåˆï¼Œä½œä¸ºä¸‹ä¸€ä¸ªVFEå±‚çš„è¾“å…¥ã€‚
    è¿™æ ·è¿ç»­å †å å‡ æ¬¡VFEå±‚åï¼Œå°±è·å¾—æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚æœ€åï¼Œä½¿ç”¨ä¸€ä¸ªElement-wise maxpool**è·å¾—æœ€åçš„ä¸€ä¸ªVoxel-wise Feature**.
    ![å±‚å VFE](./pics/å±‚å VFE.jpg)  
    ![Voxel-wise_Feature](./pics/Voxel-wise_Feature.jpg)`->`![feature](./pics/feature.jpg)  
4ä¸­çš„ä»£ç å®ç°ï¼š

```python
# Fully Connected Network
class FCN(nn.Module):
    def __init__(self, cin, cout):
        super(FCN, self).__init__()
        self.cout = cout
        # å®šä¹‰å…¨è¿æ¥å±‚
        self.linear = nn.Linear(cin, cout)
        # å®šä¹‰æ‰¹é‡å½’ä¸€åŒ–å±‚
        self.bn = nn.BatchNorm1d(cout)

    def forward(self, x):  # x(KK, t, C)
        # è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶
        # KK is the stacked k across batch(æ¯ä¸€ä¸ªbatchä¸­åŒ…å«äº†å¤šå°‘ä¸ªvoxel)
        kk, t, _ = x.shape
        # å°†è¾“å…¥å¼ é‡è§†å›¾é‡å¡‘ä¸ºäºŒç»´å¼ é‡
        x = self.linear(x.view(kk * t, -1))  # å½“å‰batchä¸­æœ‰kk* tä¸ªç‚¹ï¼Œviewæˆå˜æˆ(kk*tï¼Œ C)é€å…¥FCN
        # å¯¹å…¨è¿æ¥å±‚çš„è¾“å‡ºè¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–å’ŒReLUæ¿€æ´»
        x = F.relu(self.bn(x))
        # å°†è¾“å‡ºå¼ é‡å†æ¬¡é‡å¡‘ä¸ºä¸‰ç»´å¼ é‡
        return x.view(kk, t, -1)

# Voxel Feature Encoding layer
class VFE(nn.Module):

    def __init__(self, cin, cout):
        super(VFE, self).__init__()
        assert cout % 2 == 0
        self.units = cout // 2
        self.fcn = FCN(cin, self.units)

    def forward(self, x, mask):  # x(KK, t, C) å…¶ä¸­ï¼šmask = torch.ne(torch.max(x,2)[0], 0)åœ¨SVFEä¸­æœ‰å®šä¹‰
        # é‚£ä¹ˆmaskçš„å½¢çŠ¶ä¸º(KK, T)ï¼Œç”¨äºç­›é€‰æ‰voxelä¸­ä¸åŒ…å«ç‚¹çš„ä½ç½®(batchä¸­æœ‰KKä¸ªvoxelï¼Œå…¶ä¸­voxelä¸åŒ…å«ç‚¹çš„ä½ç½®åœ¨dim=2ä¸­ä¸€å®šå…¨ä¸º0ï¼Œæœ€å¤§å€¼ä¸€å®šä¸º0)
        # point-wise feauture
        pwf = self.fcn(x)  # (KK, t, C)
        #locally aggregated feature
        laf = torch.max(pwf, 1)[0].unsqueeze(1).repeat(1, cfg.T, 1)  # (KK, t, C)->(KK, 1, C)->(KK, T, C)
        # point-wise concat feature
        pwcf = torch.cat((pwf, laf),dim=2)  # concat(KK, t, cout//2)(KK, T, cout//2)->(KK, T, cout)
        # apply mask
        mask = mask.unsqueeze(2).repeat(1, 1, self.units * 2)  # (KK, T)->(KK, T, 1)->(KK, T, cout)
        pwcf = pwcf * mask.float()  # (KK, T, cout)* (KK, T, cout) -> (KK, T, cout)

        return pwcf  # (KK, T, cout)

# Stacked Voxel Feature Encoding
class SVFE(nn.Module):

    def __init__(self):
        super(SVFE, self).__init__()
        self.vfe_1 = VFE(7,32)
        self.vfe_2 = VFE(32,128)
        self.fcn = FCN(128,128)
    def forward(self, x):  # (KK, T, 7)
        mask = torch.ne(torch.max(x,2)[0], 0)
        x = self.vfe_1(x, mask)  # (KK, T, 32)
        x = self.vfe_2(x, mask)  # (KK, T, 128)
        x = self.fcn(x)  # (KK, T, 128)
        # element-wise max pooling
        x = torch.max(x,1)[0]  # (KK, 1, 128)->(KK, 128)
        return x  # (KK, 128)
```

### å·ç§¯å±‚Convolutional Middle Layer(CML)

> åœ¨æ‰€æœ‰Voxelä¸­åš3då·ç§¯ï¼Œè¿›ä¸€æ­¥æ‰©å¤§æ„Ÿå—é‡ï¼Œå¢åŠ æ›´å¤šçš„ä¿¡æ¯æè¿°ã€‚

ç‚¹äº‘æ•°æ®é€šè¿‡ç‰¹å¾å­¦ä¹ ç½‘ç»œåå¯ä»¥è¢«è¡¨ç¤ºæˆä¸€ä¸ª**ç¨€ç–çš„4Då¼ é‡**, ç»´åº¦è®°åš(C, D(epth), H(eight), W(idth))  
å…¶ä¸­`C`ä¸ºVoxel-wise Featureçš„å‘é‡ç»´åº¦(å³SVFEå¾—åˆ°çš„`128`ç»´ç‰¹å¾), `D, H, W`åˆ†åˆ«ä¸ºç©ºé—´çš„æ·±åº¦ã€é«˜åº¦å’Œå®½åº¦ï¼ˆ**å•ä½ä¸ºVoxelæ•°é‡**ï¼‰  

```python
# Convolutional Middle Layer
class CML(nn.Module):
    def __init__(self):
        super(CML, self).__init__()
        self.conv3d_1 = Conv3d(128, 64, 3, s=(2, 1, 1), p=(1, 1, 1))  # (128, D, H, W)->(64, D/2, H, W)
        self.conv3d_2 = Conv3d(64, 64, 3, s=(1, 1, 1), p=(0, 1, 1))  # (64, D/2 - 2, H, W)
        self.conv3d_3 = Conv3d(64, 64, 3, s=(2, 1, 1), p=(1, 1, 1))  # (64, D/4 - 1, H, W)

    def forward(self, x):  # è¾“å…¥xçš„å½¢çŠ¶ä¸º(C, D, H, W)
        x = self.conv3d_1(x)
        x = self.conv3d_2(x)
        x = self.conv3d_3(x)
        return x  # (64, D/4 - 1, H, W)
```
